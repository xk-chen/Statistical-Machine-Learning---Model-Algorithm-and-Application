{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## AdaBoost Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "INPUT:\n",
    "\n",
    "1. $m$ examples $\\mathbb{S} = \\{(x_1,y_1),\\cdots,(x_m,y_m)\\}$\n",
    "\n",
    "2. Base learner $h(x)$\n",
    "\n",
    "INITIALIZE:\n",
    "\n",
    "Weights $w_i = \\frac{1}{m}$\n",
    "\n",
    "FOR $t$ in $1:T$:\n",
    "\n",
    "   1.Train weighted examples set $(w_t,x)$ to obtain $h_t$\n",
    "   \n",
    "   2.Compute error $\\epsilon_t$\n",
    "   \n",
    "   3.Compute classifier weights $\\alpha_t$\n",
    "   \n",
    "   4.Update $w_{t+1}$\n",
    "    \n",
    "OUTPUT:\n",
    "\n",
    "$H(x) = sign(\\sum_t^T\\alpha_th_t(x))$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Derive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume final classifier $H(x)=sign(\\sum_t^T\\alpha_th_t(x))$\n",
    "\n",
    "\\begin{align*}\n",
    "err_\\mathbb{S}(H) &\\equiv \\mathbb{P}_{\\mathbb{S}}(y\\not = H(x))\\\\\n",
    "                  &= \\frac{1}{m}\\sum_{i=1}^m\\mathbb{I}\\{y_i\\not = H(x_i)\\}\\\\\n",
    "                  &\\leq \\frac{1}{m}\\sum_{i=1}^me^{-y_iH(x_i)}\\\\\n",
    "                  &=\\sum_{i=1}^m\\frac{1}{m}e^{-y_i\\sum_{t=1}^T\\alpha_th_t(x_i)}\\\\\n",
    "                  &=Z_1\\sum_{i=1}^m\\frac{1}{m}e^{-y_i\\alpha_1h_1(x_i)}e^{-y_i\\sum_{t=2}^T\\alpha_th_t(x_i)}\\\\\n",
    "\\end{align*}\n",
    "\n",
    "Let $w_i^1=\\frac{1}{m}$, $w_i^2=\\frac{\\frac{1}{m}e^{-y_i\\alpha_1h_1(x_i)}}{\\sum_{i=1}^m\\frac{1}{m}e^{-y_i\\alpha_1h_1(x_i)}}$\n",
    "\n",
    "$Z_1=\\sum_{i=1}^m\\frac{1}{m}e^{-y_i\\alpha_1h_1(x_i)}$\n",
    "\n",
    "\\begin{align*}\n",
    "err_\\mathbb{S}(H) &\\leq \\sum_{i=1}^mw_i^2e^{-y_i\\alpha_2h_2(x_i)}e^{-y_i\\sum_{t=3}^T\\alpha_th_t(x_i)}\\\\\n",
    "                  &= Z_1Z_2\\sum_{i=1}^m\\frac{w_i^2e^{-y_i\\alpha_2h_2(x_i)}}{Z_2}e^{-y_i\\sum_{t=3}^T\\alpha_th_t(x_i)}\\\\\n",
    "\\end{align*}\n",
    "\n",
    "Where $Z_2=\\sum_{i=1}^mw_i^2e^{-y_i\\alpha_2h_2(x_i)}$, and \n",
    "\n",
    "Let $w_i^3=\\frac{w_i^2e^{-y_i\\alpha_2h_2(x_i)}}{Z_2}$\n",
    "\n",
    "$$\\cdots \\cdots$$\n",
    "\n",
    "\\begin{align*}\n",
    "err_\\mathbb{S}(H)&\\leq \\prod_{t=1}^T Z_t \\sum_{i=1}^m w_i^{T+1}\\\\\n",
    "                  &= \\prod_{t=1}^TZ_t\\\\\n",
    "                  &=\\prod_{t=1}^T\\sum_{i=1}^mw_i^te^{-y_i\\alpha_th_t(x_i)}\\\\\n",
    "                  &=\\prod_{t=1}^T(\\sum_{i\\in C}w_i^te^{-\\alpha_t}+\\sum_{i\\in M}w_i^te^{\\alpha_t})\\\\\n",
    "                  &=\\prod_{t=1}^T((1-\\epsilon_t)e^{-\\alpha_t}+\\epsilon_te^{\\alpha_t})\n",
    "\\end{align*}\n",
    "\n",
    "Notice that $\\epsilon_t=\\mathbb{P}_{w^t}(y\\not=h_t(x))=\\sum_{i\\in M}w_i^t$\n",
    "\n",
    "We need to minimize the upper bound.\n",
    "\n",
    "$$g(\\alpha_t)=(1-\\epsilon_t)e^{-\\alpha_t}+\\epsilon_te^{\\alpha_t}$$\n",
    "\n",
    "$$g^\\prime(\\alpha_t)=-(1-\\epsilon_t)e^{-\\alpha_t}+\\epsilon_te^{\\alpha_t}$$\n",
    "\n",
    "Set $g^\\prime(\\alpha_t)=0$:\n",
    "\n",
    "$$\\alpha_t = \\frac{1}{2}\\log\\frac{1-\\epsilon_t}{\\epsilon_t}$$\n",
    "\n",
    "\\begin{align*}\n",
    "err_\\mathbb{S}(H)&\\leq \\prod_{t=1}^T2\\sqrt{\\epsilon_t(1-\\epsilon_t)}\\\\\n",
    "                 &=\\prod_{t=1}^T2\\sqrt{1-4\\gamma_t^2}\\\\\n",
    "                 &\\leq \\prod_{t=1}^T e^{-2\\gamma_t}\\\\\n",
    "                 &=e^{-2\\sum_{t=1}^T\\gamma_t}\n",
    "\\end{align*}\n",
    "\n",
    "Where $\\epsilon_t=\\frac{1}{2}-\\gamma_t$, and we have the identity:\n",
    "\n",
    "$$1-x\\leq e^{-x}$$\n",
    "\n",
    "Let $\\gamma = \\min_t \\gamma_t$,\n",
    "\n",
    "\n",
    "$$err_\\mathbb{S}(H)\\leq e^{-2T\\gamma^2}$$\n",
    "\n",
    "For now, we bound $err_\\mathbb{S}(H)$, and the minimum number of iterations for $\\epsilon$-error is:\n",
    "\n",
    "$$T=\\frac{1}{2\\gamma^2}\\log{\\frac{1}{\\epsilon}}$$\n",
    "\n",
    "i.e. $T = \\mathcal{O}(\\frac{1}{\\gamma^2}\\log{\\frac{1}{\\epsilon}})$ with big O notation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class base:\n",
    "    def __init__(self,X,y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "    # Given a feature, a rule \"mode\" = \">\" or \"<\", if X['feature'] \"mode\" threshold return -1 class\n",
    "    def decision_stump(self,mode,feature,threshold):\n",
    "        ret = np.ones(np.array(self.y).shape).flatten()\n",
    "        if mode == \"<\":\n",
    "            ret[self.X[:,feature] <= threshold] = -1.0\n",
    "        else:\n",
    "            ret[self.X[:,feature] >= threshold] = -1.0\n",
    "        return ret\n",
    "    def find_optimal_classifier(self,w,steps = 10):\n",
    "        min_error = np.inf\n",
    "        #obs: num of samples, feature: num of features\n",
    "        obs,feature = self.X.shape\n",
    "        optimal_classifier = {}\n",
    "        optimal_predict = np.zeros(obs)\n",
    "        #loop over all features to find the optimal feature & threshold\n",
    "        for d in range(feature):\n",
    "            feat_min = self.X[:,d].min()\n",
    "            feat_max = self.X[:,d].max()\n",
    "            step_size = (feat_max - feat_min)/float(steps)\n",
    "            for step in range(int(steps) + 1):\n",
    "                for mode in [\"<\",\">\"]:\n",
    "                    threshold = feat_min + float(step) * step_size\n",
    "                    predict_value = self.decision_stump(mode,d,threshold)\n",
    "                    rate = np.ones(obs)\n",
    "                    rate[predict_value == self.y] = 0\n",
    "                    weight_rate = np.dot(w.T, rate)\n",
    "                    if weight_rate < min_error:\n",
    "                        min_error = weight_rate\n",
    "                        optimal_classifier[\"feature\"] = d\n",
    "                        optimal_classifier[\"threshold\"] = threshold\n",
    "                        optimal_classifier[\"mode\"] = mode\n",
    "                        optimal_predict = predict_value.copy()\n",
    "        return optimal_classifier,optimal_predict,min_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AdaBoost:\n",
    "    def __init__(self,X,y,base):\n",
    "        self.X = np.array(X)\n",
    "        self.y = np.array(y)\n",
    "        self.base = base       \n",
    "    def train(self,T):\n",
    "        #alpha[i]: the weight of the i-th classifier\n",
    "        #boost: collection of weak classifier\n",
    "        #w: the weight of each point\n",
    "        #sign(f): the combination of previous classifiers for now\n",
    "        #f_error: the error rate of current classifier\n",
    "        self.alpha = []\n",
    "        self.h = {}    \n",
    "        self.boost = []\n",
    "        self.w = np.ones(self.y.shape[0])*1.0/len(y)       \n",
    "        self.f = np.zeros(self.y.shape)        \n",
    "        self.f_error = np.inf\n",
    "        error_list = []\n",
    "        for t in range(T):\n",
    "            self.h[t] = self.base(self.X,self.y)\n",
    "            classifier,predict,error = self.h[t].find_optimal_classifier(self.w)\n",
    "            self.boost.append(classifier)\n",
    "            self.alpha.append(0.5 * np.log((1.0-error)/error))# Add Laplacian smooth\n",
    "            self.f = self.f + self.alpha[t] * predict\n",
    "            self.f_error = np.dot((np.sign(self.f) != self.y),np.ones(self.y.shape[0]))/float(self.y.shape[0])\n",
    "            error_list.append(self.f_error)\n",
    "            if self.f_error == 0:\n",
    "                break\n",
    "            w_next = self.w * np.exp(-self.alpha[t]*self.y*predict)\n",
    "            self.w = (w_next/w_next.sum())\n",
    "        return self.boost,error_list\n",
    "    #flag: single input for 0, multi-input for 1\n",
    "    def classifier(self,x,flag = 1):\n",
    "        if flag == 0:\n",
    "            x = x[np.newaxis]\n",
    "        base_result = np.zeros(x.shape[0])\n",
    "        for i in range(len(self.boost)):\n",
    "            label = np.ones(x.shape[0])\n",
    "            if self.boost[i]['mode'] == '>':\n",
    "                label[np.where(x[:,self.boost[i]['feature']] >= self.boost[i]['threshold'])] = -1\n",
    "            else:\n",
    "                label[np.where(x[:,self.boost[i]['feature']] <= self.boost[i]['threshold'])] = -1\n",
    "            base_result += base_result + self.alpha[i] * label\n",
    "        return np.sign(base_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.array([[1,2],[2,3],[3,4],[3,2],[3,1],[4,4],[5,4],[5,2],[5,1]])\n",
    "y = np.array([1,1,-1,-1,-1,-1,-1,1,1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "adaboost = AdaBoost(X,y,base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([{'feature': 0, 'mode': '>', 'threshold': 2.2000000000000002},\n",
       "  {'feature': 1, 'mode': '>', 'threshold': 3.1000000000000001},\n",
       "  {'feature': 0, 'mode': '<', 'threshold': 4.2000000000000002}],\n",
       " 0.0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adaboost.train(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.62638148424768403, 0.89587973461402748, 0.97295507452765662]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adaboost.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5, 5.5)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJBXIcpekAlnuklQgy12SCmS5S1KB/g80gYTmoJb/aAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xbe807b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = {1:'r',-1:'b'}\n",
    "l = []\n",
    "for i in y:\n",
    "    l.append(d[i])\n",
    "plt.scatter(X[:,0],X[:,1],color=l)\n",
    "plt.vlines(2.2,0.5,4.5)\n",
    "plt.hlines(3.1,0.5,5.5)\n",
    "plt.vlines(4.2,0.5,4.5)\n",
    "plt.ylim(0.5,4.5)\n",
    "plt.xlim(0.5,5.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adaboost.classifier(np.array([1,1]),flag=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
