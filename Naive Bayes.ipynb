{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayes Theorem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\\begin{theorem}[Bayes theorem]\n",
    "\n",
    "We input features $X$, then compute $\\mathbb{P}(y=i)$, $\\mathbb{P}(X=x)$ and $\\mathbb{P}(X=x\\mid y=i)$, we will obtain the posterior.\n",
    "\n",
    "$$\\mathbb{P}(y=i\\mid X=x)=\\frac{\\mathbb{P}(X=x\\mid y=i)\\mathbb{P}(y=i)}{\\mathbb{P}(X=x)}$$\n",
    "\\end{theorem}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume the data has $m$ features. According to the Bayes theorem, we need to compute the joint distribution of features and class. To do this, we have to compute $2^m$ combinations for those binary features.\n",
    "\n",
    "Naive Bayes classifiers assume that given class label $Y$ the features are conditionally independent of each other:\n",
    "\n",
    "$$P(X\\mid y)=\\prod_jP_j(X_j\\mid y)$$\n",
    "\n",
    "\n",
    "The full classification rule is:\n",
    "\n",
    "\\begin{align*}\n",
    "\\hat{y}&=\\arg\\max_i\\mathbb{P}(y=i\\mid X)\\\\\n",
    "       &=\\arg\\max_i\\frac{\\mathbb{P}(X=x\\mid y=i)\\mathbb{P}(Y=i)}{\\mathbb{P}(X=x)}\\\\\n",
    "       &=\\arg\\max_i\\prod_j\\mathbb{P}_j(X_j=x_j\\mid y=i)\\mathbb{P}(y=i)\n",
    "\\end{align*}\n",
    "\n",
    "And we can estimate $\\mathbb{P}(y=i)$ by $\\frac{n_i}{n}$ (i.e. $y\\sim Multinomial(p_1,p_2,\\dots,p_m)$), estimate $\\mathbb{P}_j(X_j=x_j\\mid y=i)$ by $\\frac{n_{ij}}{n_i}$ - only compute $m$ probabilities for the joint probability! \n",
    "\n",
    "If the assumption holds, NB is optimal classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "x=np.array([[1,1,1],[0,0,0],[1,0,0],[0,0,1],[1,1,0],[1,0,1]])\n",
    "y=np.array([1,0,1,1,0,1])\n",
    "\n",
    "def Naive_Bayes(f):\n",
    "    p_1=y.sum()/len(y)\n",
    "    p_0=1-p_1\n",
    "    p=np.zeros(len(f))\n",
    "    p_c=np.zeros(len(f))\n",
    "    q_c=np.zeros(len(f))\n",
    "    for i in range(len(f)):\n",
    "        if f[i]==0:\n",
    "            p_c[i]=1-x[np.where(y==1)][:,i].sum()/len(x[np.where(y==1)])\n",
    "            q_c[i]=1-x[np.where(y==0)][:,i].sum()/len(x[np.where(y==0)])\n",
    "        else:\n",
    "            p_c[i]=x[np.where(y==1)][:,i].sum()/len(x[np.where(y==1)])\n",
    "            q_c[i]=1-x[np.where(y==0)][:,i].sum()/len(x[np.where(y==0)])\n",
    "    posterior_1=p_c.prod()*p_1\n",
    "    posterior_2=q_c.prod()*p_0\n",
    "    if (posterior_1>posterior_2):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "def validation(sample,output):\n",
    "    count=0\n",
    "    for i in range(len(sample)):\n",
    "        if (Naive_Bayes(sample[i])==output[i]):\n",
    "            count=count+1\n",
    "    print(count/len(output))\n",
    "x_test=np.array([[0,1,0],[0,1,1]])\n",
    "y_test=np.array([0,0])\n",
    "validation(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Bayes Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{theorem}[Continuous version of Bayes theorem]\n",
    "\n",
    "$$\\mathbb{P}(Y=y_k\\mid X_1,X_2,\\cdots,X_n)=\\frac{\\mathbb{P}(Y=y_k)\\prod_{i=1}^n\\mathbb{P}(X_i\\mid Y=y_k)}{\\sum_j\\mathbb{P}(Y=y_j)\\prod_{i=1}^n\\mathbb{P}(X_i\\mid Y=y_j)}$$\n",
    "\n",
    "Where $\\mathbb{P}(X_i\\mid Y=y_k)$ follows a Gaussian distribution.\n",
    "\\end{theorem}\n",
    "\n",
    "Normal Distribution: $$f(x;\\mu,\\Sigma)=\\frac{1}{(2\\pi)^\\frac{p}{2}\\left\\vert\\Sigma\\right\\vert^\\frac{1}{2}}e^{-(x-\\mu)^T\\Sigma^{-1}(x-\\mu)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "\n",
    "# Compute the multinormal distribution pdf with expectation mu and covariance sigma\n",
    "def Gaussian_function(x,mu,sigma):\n",
    "    return 1/((np.sqrt(2*np.pi))**len(mu)*(np.linalg.det(sigma))**0.5)*\\\n",
    "    np.exp(np.dot(np.dot(-(x-mu),np.linalg.inv(sigma)),(x-mu))/2)\n",
    "# Parametric inference of mu and sigma (use MLE)\n",
    "def parametric_estimation(x,y):\n",
    "# The shape of mu,sigma is the number of classes by the number of features\n",
    "    mu_trans=np.zeros((len(np.unique(y)),x.shape[1]))\n",
    "    sigma_trans=np.zeros((len(np.unique(y)),x.shape[1],x.shape[1]))\n",
    "    prior=np.zeros(len(np.unique(y)))\n",
    "    for i in range(len(np.unique(y))):\n",
    "# For every class, compute the mean and cov (about features)\n",
    "        mu_trans[i]=np.mean(x[np.where(y==i)],axis=0)\n",
    "        sigma_trans[i]=(np.cov(x[np.where(y==i)].T))\n",
    "        prior[i]=len(np.where(y==i))/len(y)\n",
    "    return (mu_trans,sigma_trans,prior)\n",
    "def Gaussian_NB(test_x,x,y):\n",
    "    mu,sigma,prior=parametric_estimation(x,y)\n",
    "    posterior=np.zeros(len(mu))\n",
    "    for i in range(len(mu)):\n",
    "        posterior[i]=Gaussian_function(test_x,mu[i],sigma[i])*prior[i]\n",
    "    return np.argmax(posterior)\n",
    "\n",
    "def test(sample,output,N):\n",
    "# Shuffle the population\n",
    "    randomize = np.arange(len(sample))\n",
    "    np.random.shuffle(randomize)\n",
    "    sample = sample[randomize]\n",
    "    output = output[randomize]\n",
    "# Divide the training sample and testing sample\n",
    "    x=sample[:N]\n",
    "    y=output[:N]\n",
    "    x_1=sample[N:]\n",
    "    y_1=output[N:]\n",
    "    count=0\n",
    "    for i in range(len(x_1)):\n",
    "        if (Gaussian_NB(x_1[i],x,y)==y_1[i]):\n",
    "            count=count+1\n",
    "    print(count/len(x_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.96\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "data=load_iris().data\n",
    "target=load_iris().target\n",
    "test(data,target,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.947791164659\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "data=load_breast_cancer().data\n",
    "target=load_breast_cancer().target\n",
    "test(data,target,320)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
