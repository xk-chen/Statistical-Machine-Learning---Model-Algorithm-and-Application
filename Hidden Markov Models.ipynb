{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hidden Markov Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hidden Markov Model** is a statistical model in which the system being modeled is assumed to be a Markov process with underlying states.\n",
    "\n",
    "In simpler Markov models, the states is directly visible to the learner, and the transition probabilities are the only parameters, while in the hidden Markov models, the state is not directly visible, but the output, dependent on the state, is visible. Each state has a distribution over the outputs.\n",
    "\n",
    "A hidden Markov model can be considered a generalization of a mixture model where the hidden variables, which control the mixture component to be select for each observation, are related through a Markov process rather than independent of each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider discrete HMMs of length $T$(i.e. each observation sequence is $T$ observations long). Let the space of observations be $X=\\{1,2,\\dots,N\\}$, and the space of states $Z=\\{1,2,\\dots,M\\}$. \n",
    "\n",
    "Define a HMM model $\\theta=(\\pi,A,B)$, where $\\pi$ is the initial state matrix(i.e. $\\pi_i=\\mathbb{P}(z_1=i)$), $A$ is the state transition matrix(i.e. $A_{ij}=\\mathbb{P}(z_{t+1}=j\\mid z_{t}=i)$), and $B$ is the emission matrix($B_i(j)=\\mathbb{P}(x_t=j\\mid z_t=i)$).\n",
    "\n",
    "Assume we have $D$ iid observation sequences. Let $\\mathcal{X}=\\{X^{(1)},X^{(2)},\\dots,X^{(D)}\\}$. Often, the state set $\\mathcal{Z}$ is unknown to the learner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Properties of HMMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HMM has Markov Property:\n",
    "\n",
    "*  $\\mathbb{P}(z_{t+1}\\mid z_1,\\dots,z_t)=\\mathbb{P}(z_{t+1}\\mid z_t)$.\n",
    "*  The Markov chain of hidden states is homogeneous(the transition matrix $A$ is time-invariant).\n",
    "*  The observations only depend on the state at current time $t$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fundamental questions of HMMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference in HMMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.Given model $\\theta=(\\pi,A)$ without observation, how to compute $P(Z)$ and $\\mathbb{P}(z_t = i)$?\n",
    " \n",
    " By induction: $$p_1(i)=\\pi_i $$ \n",
    " \n",
    " $$ p_t(i)=\\sum_j\\mathbb{P}(z_t=i\\mid z_{t-1}=j)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.Given observation set $X$, and model $\\theta=(\\pi,A,B)$,how to compute $P(Z\\mid X)$ and $\\mathbb{P}(z_t=i\\mid X)$?\n",
    "\n",
    " Define forward probability $\\alpha_t(i)=\\mathbb{P}(x_1,x_2,\\dots,x_t\\wedge z_t=i)$, one can show that \n",
    " \n",
    " $$\\alpha_1(i)=\\mathbb{P}(x_1 \\wedge z_1=i)=\\mathbb{P}(x_1 \\mid z_1=i)\\mathbb{P}(z_1=i)=B_i(x_1)\\pi_i$$\n",
    " \n",
    " $$\\alpha_{t+1}(i)=\\sum_jB_i(x_{t+1})A_{ji}\\alpha_t(j)$$\n",
    " \n",
    "\\begin{proof}\n",
    "\n",
    "\\begin{align*}\n",
    "\\sum_j\\alpha_t(j)A_{ji}B_i(x_{t+1})&=\\sum_j\\mathbb{P}(x_1,x_2,\\dots,x_t\\wedge z_t=j)\\mathbb{P}(z_{t+1}=i\\mid z_t=j)\\mathbb{P}(x_{t+1}\\mid z_{t+1}=i)\\\\\n",
    "&=\\sum_j \\mathbb{P}(x_1,x_2,\\dots,x_t\\wedge z_t=j)\\mathbb{P}(z_{t+1}=i\\mid z_t=j)\\mathbb{P}(x_{t+1}\\mid z_{t+1}=i,z_t=j)\\\\\n",
    "&=\\sum_j \\mathbb{P}(x_1,x_2,\\dots,x_t\\wedge z_t=j)\\mathbb{P}(x_{t+1},z_{t+1}=i\\mid z_t=j)\\\\\n",
    "&=\\sum_j \\mathbb{P}(x_1,x_2,\\dots,x_t\\wedge z_t=j)\\mathbb{P}(x_{t+1},z_{t+1}=i\\mid z_t=j,x_1,x_2,\\dots,x_t)\\\\\n",
    "&=\\sum_j \\mathbb{P}(x_1,x_2,\\dots,x_{t+1},z_t=j,z_{t+1}=i)\\\\\n",
    "&=\\mathbb{P}(x_1,x_2,\\dots,x_{t+1},z_{t+1}=i)\\\\\n",
    "&=\\alpha_{t+1}(i)\n",
    "\\end{align*}\n",
    "\n",
    "\\end{proof}\n",
    "\n",
    " We can use Bayes rule:\n",
    " \n",
    " $$P(z_t=i\\mid X)=\\frac{P(X\\mid z_t=i)P(z_t=i)}{P(X)}=\\frac{P(X\\wedge z_t=i)}{P(X)}=\\frac{\\alpha_t(i)}{\\sum_j\\alpha_t(j)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.Given observation set $X$, and model $\\theta=(\\pi,A,B)$, how to find the most probable path such that $P(Z^*\\mid X)=\\arg\\max_ZP(Z\\mid X)$?  \n",
    "\n",
    "Here we have:\n",
    "\n",
    "$$\\arg\\max_ZP(Z\\mid X)=\\arg\\max_Z\\frac{P(X\\mid Z)P(Z)}{P(X)}=\\arg\\max_ZP(X\\mid Z)P(Z)=\\arg\\max_ZP(X,Z)$$\n",
    "\n",
    "Viterbi Algorithm:\n",
    "\n",
    "Given the defination that:\n",
    "\n",
    "$$\\delta_t(i)=\\max_{z_1,\\dots,z_{t-1}}\\mathbb{P}(z_1,\\dots,z_{t-1}\\wedge z_t=i\\wedge x_1,\\dots,x_t)$$\n",
    "\n",
    "In other words, we are interested in the most likely path from $1$ to $t$ that:\n",
    "\n",
    "1.Ends in state $i$.\n",
    "\n",
    "2.Produces observations $x_1,\\dots,x_t$.\n",
    "\n",
    "It is obvious that:\n",
    "\n",
    "$$\\delta_1(i) = \\mathbb{P}(z_1=i\\wedge x_1)=\\mathbb{P}(z_1=i)\\mathbb{P}(x_1\\mid z_1=i)=\\pi_iB_i(x_1)$$\n",
    "\n",
    "\n",
    "\\begin{align*}\n",
    "\\delta_{t+1}(i)&=\\max_{z_1,\\dots,z_{t}}\\mathbb{P}(z_1,\\dots,z_{t}\\wedge z_{t+1}=i\\wedge x_1,\\dots,x_{t+1})\\\\\n",
    "&= \\max_j \\mathbb{P}(z_1,\\dots,z_{t-1}\\wedge z_t=j\\wedge x_1,\\dots,x_t)\\mathbb{P}(z_{t+1}=i\\mid z_t=j)\\mathbb{P}(x_{t+1}\\mid z_{t+1}=i)\\\\\n",
    "&= \\max_j \\delta_t(j)A_{ji}B_i(x_{t+1})\n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "We use dynamic programming for solving $\\delta_t(i)$. And $P(Z^*\\mid X)=\\arg\\max_ZP(X,Z)=\\arg\\max_j\\delta_t(j)$ for $\\forall t$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learning HMMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.Supervised learning framework\n",
    "\n",
    "In this scenario, assume we can observe the set of states $\\mathcal{Z}$, we using maximum likelihood estimation to learn the model.\n",
    "\n",
    "Initial probabilities:\n",
    "\n",
    "$$\\pi^*=\\arg\\max_\\pi\\prod_{d=1}^D\\pi_{z_1^{(d)}}B_{z_1^{(d)}}(x_1^{(d)})\\prod_{t=2}^TP(z_t\\mid z_{t-1})\\propto \\arg\\max_\\pi\\prod_{k=1}^D\\pi_{z_1^{(d)}}$$\n",
    "\n",
    "Transition probabilities:\n",
    "\n",
    "$$A_{ij}^*=\\arg\\max_{A_{ij}}\\prod_{d=1}^D\\pi_{z_1^{(d)}}B_{z_1^{(d)}}(x_1^{(d)})\\prod_{t=2}^TP(z_t=j\\mid z_{t-1}=i)\\propto \\arg\\max_{A_{ij}}\\prod_{t=2}^TP(z_t=j\\mid z_{t-1}=i)$$\n",
    "\n",
    "Emission probabilities:\n",
    "\n",
    "$$B_i^*(j)=\\hat{\\mathbb{P}}(x_t=j\\mid z_t=i)_{MLE}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.Unsupervised learning framework\n",
    "\n",
    "Define backward probability $\\beta_t(i)=\\mathbb{P}(x_{t+1},\\dots,x_T\\mid z_t=i)$, and it holds that\n",
    "\n",
    "$$\\beta_T(i)=1$$\n",
    "\n",
    "$$\\beta_t(i)=\\sum_j A_{ij}B_j(x_{t+1})\\beta_{t+1}(j)$$\n",
    "\n",
    "\\begin{proof}\n",
    "\n",
    "\\begin{align*}\n",
    "\\sum_j A_{ij}B_j(x_{t+1})\\beta_{t+1}(j)&=\\sum_j\\mathbb{P}(z_{t+1}=j\\mid z_t=i)\\mathbb{P}(x_{t+1}\\mid z_{t+1}=j)\\mathbb{P}(x_{t+2},\\dots,x_T\\mid z_{t+1}=j)\\\\\n",
    "&=\\sum_j\\mathbb{P}(z_{t+1}=j\\mid z_t=i,z_{t+1}=j)\\mathbb{P}(x_{t+1}\\mid z_{t+1}=j)\\mathbb{P}(x_{t+2},\\dots,x_T\\mid z_{t+1}=j)\\\\\n",
    "&=\\sum_j\\mathbb{P}(x_{t+1},z_{t+1}=j\\mid z_t=i)\\mathbb{P}(x_{t+2},\\dots,x_T\\mid x_{t+1},z_{t+1}=j,z_t=i)\\\\\n",
    "&=\\sum_j\\mathbb{P}(x_{t+1},x_{t+2},\\dots,x_T,z_{t+1}=j\\mid z_t=i)\\\\\n",
    "&=\\sum_j\\mathbb{P}(x_{t+1},x_{t+2},\\dots,x_T\\mid z_t=i)\\\\\n",
    "&=\\beta_t(i)\n",
    "\\end{align*}\n",
    "\n",
    "\\end{proof}\n",
    "\n",
    "\n",
    "$$S_t(i)\\equiv\\mathbb{P}(z_t=i\\mid x_1,\\dots,x_T)=\\frac{\\alpha_t(i)\\beta_t(i)}{\\sum_j\\alpha_t(j)\\beta_t(j)}=\\frac{\\mathbb{P}(x_1,\\dots,x_t,z_t=i)\\mathbb{P}(x_{t+1},\\dots,x_T\\mid z_t=i)}{\\sum_j\\mathbb{P}(x_1,\\dots,x_t,z_t=j)\\mathbb{P}(x_{t+1},\\dots,x_T\\mid z_t=j)}=\\frac{\\mathbb{P}(x_1,\\dots,x_T,z_t=i)}{\\sum_k\\mathbb{P}(x_1,\\dots,x_T,z_t=k)}$$\n",
    "\n",
    "\\begin{align*}\n",
    "S_t(i,j)&\\equiv \\mathbb{P}(z_t=i,z_{t+1}=j\\mid x_1,\\dots,x_T)\\\\\n",
    "&=\\frac{\\alpha_t(i)A_{ij}B_j(x_{t+1})\\beta_{t+1}(j)}{\\sum_j\\alpha_t(j)\\beta_t(j)}\\\\\n",
    "&=\\frac{\\mathbb{P}(x_1,\\dots,x_t,z_t=i)\\mathbb{P}(z_{t+1}=j\\mid z_t=i)\\mathbb{P}(x_{t+1}\\mid z_{t+1}=j)\\mathbb{P}(x_{t+2},\\dots,x_T\\mid z_{t+1}=j)}{\\sum_k\\mathbb{P}(x_1,\\dots,x_T,z_t=k)}\\\\\n",
    "&=\\frac{\\mathbb{P}(x_1,\\dots,x_T,z_t=i,z_{t+1}=j)}{\\sum_k\\mathbb{P}(x_1,\\dots,x_T,z_t=k)}\n",
    "\\end{align*}\n",
    "\n",
    "We can estimate parameters by $S_t(i)$ and $S_t(i,j)$:\n",
    "\n",
    "$$A_{ij}=\\mathbb{P}(z_{t+1}=j\\mid z_{t}=i)\\approx\\frac{\\sum_tS_t(i,j)}{\\sum_k\\sum_tS_t(i,k)}$$\n",
    "\n",
    "$$B_i(j)=\\mathbb{P}(x_t=j\\mid z_t=i)\\approx\\frac{\\sum_{t\\mid x_t=j}S_t(i)}{\\sum_k\\sum_{t\\mid x_t=j}S_t(k)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baum-Welch Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input: Observation $x_1,x_2,\\dots,x_T$ and the number of states $N$.\n",
    "\n",
    "1.Guess model parameters $A$, $\\pi$ and $B$.\n",
    "\n",
    "2.E-step: Compute $S_t(i)$ and $S_t(i,j)$.\n",
    "\n",
    "3.M-step: Use $S$ to compute $A$ and $B$ (MLE).\n",
    "\n",
    "4.If converge, to 5. Else to 2.\n",
    "\n",
    "5.Model output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baum-Welch is an iterative procedure for estimating $\\theta^*$ from only $\\mathcal{X}$. It works by maximizing log-likelihood, and updating the current model to be closer to the optimal model. Each step will increase the log-likelihood.\n",
    "\n",
    "We can explain the algorithm as:\n",
    "\n",
    "1.Compute $Q(\\theta,\\theta^s)=\\sum_{z\\in\\mathcal{Z}}\\log\\[P(\\mathcal{X},z;\\theta)\\]P(z\\mid\\mathcal{X};\\theta^s)$.\n",
    "\n",
    "2.Set $\\theta^{s+1}=\\arg\\max_\\theta Q(\\theta,\\theta^s)$\n",
    "\n",
    "Where $$P(z,\\mathcal{X};\\theta)=\\prod_{d=1}^D\\big(\\pi_{z_1^{(d)}}B_{z_1^{(d)}}(x_1^{(d)})\\prod_{t=2}^TA_{z_{t-1}^{(d)}z_t^{(d)}}B_{z_t^{(d)}}(x_t^{(d)})\\big)$$\n",
    "\n",
    "Take logarithm we have:\n",
    "\n",
    "$$\\log P(z,\\mathcal{X};\\theta)=\\sum_{d=1}^D\\big[\\log{\\pi_{z_1^{(d)}}}+\\sum_{t=2}^T\\log{A_{z_{t-1}^{(d)}z_t^{(d)}}}+\\sum_{t=1}^T\\log{B_{z_t^{(d)}}(x_t^{(d)})}\\big]$$\n",
    "\n",
    "Note that $P(z,\\mathcal{X})=P(z\\mid\\mathcal{X})P(\\mathcal{X})$ and $P(\\mathcal{X})$ is a constant (not affected by $\\theta$).Hence,\n",
    "\n",
    "$$\\arg\\max_\\theta \\sum_{z\\in\\mathcal{Z}}\\log{[P(\\mathcal{X},z;\\theta)]}P(z\\mid\\mathcal{X};\\theta^s)=\\arg\\max_\\theta \\sum_{z\\in\\mathcal{Z}}\\log{[P(\\mathcal{X},z;\\theta)]}P(z,\\mathcal{X};\\theta^s)=\\arg\\max_\\theta \\hat{Q}(\\theta,\\theta^s)$$\n",
    "\n",
    "Plugging $\\log P(z,\\mathcal{X};\\theta)$ into $\\hat{Q}(\\theta,\\theta^s)$:\n",
    "\n",
    "$$\\hat{Q}(\\theta,\\theta^s)=\\sum_{z\\in\\mathcal{Z}}\\sum_{d=1}^D\\big[\\log{\\pi_{z_1^{(d)}}}+\\sum_{t=2}^T\\log{A_{z_{t-1}^{(d)}z_t^{(d)}}}+\\sum_{t=1}^T\\log{B_{z_t^{(d)}}(x_t^{(d)})}\\big]P(z,\\mathcal{X};\\theta^s)$$\n",
    "\n",
    "Let $\\hat{L}(\\theta,\\theta^s)$ be the Lagrangian:\n",
    "\n",
    "$$\\hat{L}(\\theta,\\theta^s)=\\hat{Q}(\\theta,\\theta^s)-\\lambda_\\pi\\big(\\sum_{i=1}^M\\pi_i-1\\big)-\\sum_{i=1}^M\\lambda_{A_i}\\big(\\sum_{i=j}^MA_{ij}-1\\big)-\\sum_{i=1}^M\\lambda_{B_i}\\big(\\sum_{j=1}^NB_i(j)-1\\big)$$\n",
    "\n",
    "Solve it we have:\n",
    "\n",
    "$$\\pi_i^{(s+1)}=\\frac{1}{D}\\sum_{d=1}^DP(z_1^{(d)}=i\\mid X^{(d)};\\theta^s)$$\n",
    "\n",
    "$$A_{ij}^{(s+1)}=\\frac{\\sum_{d=1}^D\\sum_{t=2}^TP(z_{t-1}^{(d)}=i,z_t^{(d)}=j\\mid X^{(d)};\\theta^s)}{\\sum_{d=1}^D\\sum_{t=2}^TP(z_{t-1}^{(d)}=i\\mid X^{(d)};\\theta^s)}$$\n",
    "\n",
    "$$B_i^{(s+1)}(j)=\\frac{\\sum_{d=1}^D\\sum_{t=1}^TP(z_t^{(d)}=i\\mid X^{(d)};\\theta^s)\\mathbb{I}\\{x_t^{(d)}=j\\}}{\\sum_{d=1}^D\\sum_{t=1}^TP(z_t^{(d)}=i\\mid X^{(d)};\\theta^s)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class HMM:\n",
    "    \n",
    "    def __init__(self, state_num):\n",
    "        \n",
    "        self.M = state_num\n",
    "       \n",
    "    \n",
    "    # Encode for variable inputs\n",
    "    def encode(self, seq):\n",
    "        \n",
    "        self.encode_dict = dict(zip(set(seq),range(len(set(seq)))))\n",
    "        encode_seq = []\n",
    "        for i in seq:\n",
    "            encode_seq.append(self.encode_dict[i])\n",
    "        return encode_seq   \n",
    "        \n",
    "        \n",
    "    # Decode after encode\n",
    "    def decode(self, seq):\n",
    "        \n",
    "        self.decode_dict = dict(zip(self.encode_dict.values(), self.encode_dict.keys()))\n",
    "        decode_seq = []\n",
    "        for i in seq:\n",
    "            decode_seq.append(self.decode_dict[i])\n",
    "        return decode_seq\n",
    "        \n",
    "        \n",
    "    def learning(self, sequence, max_iteration):\n",
    "        \n",
    "        self.obs = np.array(self.encode(sequence))#np.array(sequence)[np.newaxis,:]\n",
    "        # Number of observations\n",
    "        self.N = len(np.unique(self.obs))\n",
    "        # Sequence length\n",
    "        self.T = self.obs.shape[0]\n",
    "        # Number of sequences\n",
    "        #self.D = self.obs.shape[0]\n",
    "        # Initialize transition matrix\n",
    "        A_unscaled = np.random.rand(self.M, self.M)\n",
    "        self.A = (A_unscaled/A_unscaled.sum(axis=0)) \n",
    "        # Initialize emission matrix\n",
    "        self.B = np.random.rand(self.M, self.N)\n",
    "        for i in range(self.M):\n",
    "            self.B[i] = 1.0 * self.B[i]/self.B.sum(axis = 1)[i]\n",
    "        # Assign equal probabilities for each state\n",
    "        self.pi = np.repeat(1.0/self.M, self.M)\n",
    "        \n",
    "        \n",
    "        # Return matrix S_i at time t\n",
    "        def compute_S_i(t):\n",
    "            \n",
    "            # Initialize forward probability\n",
    "            alpha = self.pi * self.B[:,self.obs[0]]\n",
    "            # Initialize backward probability\n",
    "            beta = np.ones(self.M)\n",
    "            beta_t_plus_one = beta\n",
    "            # Forward algorithm\n",
    "            for i in range(0, t):\n",
    "                alpha = np.dot(alpha, self.A) * self.B[:, self.obs[i + 1]]\n",
    "            # Backward algorithm\n",
    "            for i in range(self.T - 2, t - 1, -1):\n",
    "                if i == t:\n",
    "                    beta_t_plus_one = beta\n",
    "                beta = np.dot(self.A, beta * self.B[:, self.obs[i + 1]])\n",
    "            return 1.0 * alpha * beta / (alpha * beta).sum()\n",
    "\n",
    "        \n",
    "        # Return matrix S_ij at time t    \n",
    "        def compute_S_ij(t):\n",
    "            \n",
    "            # Initialize forward probability\n",
    "            alpha = self.pi * self.B[:,self.obs[0]]\n",
    "            # Initialize backward probability\n",
    "            beta = np.ones(self.M)\n",
    "            beta_t_plus_one = beta\n",
    "            # Forward algorithm\n",
    "            for i in range(0, t):\n",
    "                alpha = np.dot(alpha, self.A) * self.B[:, self.obs[i + 1]]\n",
    "            # Backward algorithm\n",
    "            for i in range(self.T - 2, t - 1, -1):\n",
    "                if i == t:\n",
    "                    beta_t_plus_one = beta\n",
    "                beta = np.dot(self.A, beta * self.B[:, self.obs[i + 1]])\n",
    "            return self.A.T * np.repeat(beta_t_plus_one, self.M).reshape(self.M, self.M)\\\n",
    "                   * (self.B[:,self.obs[t + 1]].reshape(self.M, 1) * alpha.reshape(1, self.M)) / (alpha * beta).sum()\n",
    "        \n",
    "        \n",
    "        # Update transition matrix and emission matrix\n",
    "        def parameters_updating():\n",
    "            \n",
    "            # Set of S_i & S_ij at all time\n",
    "            list_S_i = []\n",
    "            list_S_ij = []\n",
    "            for t in range(0, self.T):\n",
    "                list_S_i.append(compute_S_i(t))\n",
    "            for t in range(0, self.T - 1):\n",
    "                list_S_ij.append(compute_S_ij(t)) \n",
    "            # Record the S_i matrix loop all observations at all time\n",
    "            list_final = []\n",
    "            for j in range(0, self.N):\n",
    "                # Record the S_i matrix at all time at which observations is j \n",
    "                list_partial = []\n",
    "                for t in range(0, self.T):\n",
    "                    if self.obs[t] == j:\n",
    "                        list_partial.append(list_S_i[t])\n",
    "                list_final.append(list_partial)\n",
    "            for i in range(self.N):\n",
    "                self.B[:,i] = np.array(sum(list_final[i]))\n",
    "            return (list_S_i[0], sum(list_S_ij)/sum(list_S_i[: -1]), (self.B.T/sum(list_S_i)).T)\n",
    "        \n",
    "        \n",
    "        # Baum-Welch Algorithm\n",
    "        for i in range(max_iteration):\n",
    "            self.pi, self.A, self.B = parameters_updating()\n",
    "            \n",
    "        return self.pi, self.A, self.B\n",
    "    \n",
    "    \n",
    "    # Viterbi Algorithm\n",
    "    def inference(self, sequence, initial_matrix, transition_matrix, emission_matrix):\n",
    "        \n",
    "        self.pi = initial_matrix\n",
    "        self.A = transition_matrix\n",
    "        self.B = emission_matrix\n",
    "        self.obs = np.array(self.encode(sequence))\n",
    "        self.T = self.obs.shape[0]\n",
    "        # delta[j,t] records the probability of end with state j at time t \n",
    "        self.delta = np.zeros((self.M, self.T))\n",
    "        # psi[j,t] records current state is j at time t - 1\n",
    "        self.psi = np.zeros((self.M, self.T)) \n",
    "        # Initialize delta & psi\n",
    "        self.delta[:,0] = self.pi * self.B[:,self.obs[0]]\n",
    "        self.psi[:,0] = np.zeros(self.M) - 1\n",
    "        result = np.zeros(self.T)\n",
    "        for t in range(1, self.T):\n",
    "            # Update delta\n",
    "            self.delta[:, t] = np.max(self.A.T * np.dot(self.B[:, self.obs[t]].reshape(self.M, 1), \\\n",
    "                                      self.delta[:, t - 1].reshape(1, self.M)), axis = 1)\n",
    "            # Update psi\n",
    "            self.psi[:, t] = np.argmax(np.repeat(self.delta[:, t - 1], self.M).reshape(self.M, self.M).T * A.T, axis = 1) \n",
    "        # Find the states that maximize the delta at each time t\n",
    "        index = np.argmax(self.delta, axis=0)\n",
    "        for i in range(len(index)):\n",
    "                result[i] = int(self.psi[:, i][index[i]])\n",
    "        # Correct the first max_probability\n",
    "        result[0] = np.argmax(self.delta[:,0])\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A = np.array([[0.5,0.2,0.3],[0.3,0.5,0.2],[0.2,0.3,0.5]])\n",
    "B = np.array([[0.5,0.5],[0.4,0.6],[0.7,0.3]])\n",
    "pi = np.array([0.2,0.4,0.4])\n",
    "obs = [1,2,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pi: [ 0.01719123  0.98280877  0.        ] \n",
      "\n",
      "A: [[ 0.   0.   0.5]\n",
      " [ 0.   0.   0.5]\n",
      " [ 1.   1.   0. ]] \n",
      "\n",
      "B: [[ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]]\n"
     ]
    }
   ],
   "source": [
    "h = HMM(3)\n",
    "parameters = h.learning(obs, 50)\n",
    "print \"pi:\", parameters[0], \"\\n\"\n",
    "\n",
    "print \"A:\", parameters[1], \"\\n\"\n",
    "\n",
    "print \"B:\", parameters[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.,  2.,  2.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.inference(obs, pi, A, B)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "161px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
