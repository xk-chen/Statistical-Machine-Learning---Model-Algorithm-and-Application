{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Stochastic process** is a family of random variables $\\{X_t:t\\in\\mathcal{T}\\}$, where each $X_t$ takes some value in the state space, denote $\\mathbb{S}$. We call $\\mathcal{T}$ the index set, often we refer to the index set as time.\n",
    "\n",
    "### Various stochastic processes\n",
    "\n",
    "1. Discrete time, discrete state: Markov chains\n",
    "\n",
    "2. Discrete time, continuous state: auto-regressive model, Kalman filter, $X_{t+1}=AX_t+\\epsilon_t$\n",
    "\n",
    "3. Continuous time, discrete state: Birth & Death process\n",
    "\n",
    "4. Continuous time, continuous state: Brownian motion, $\\lim_{\\delta\\rightarrow 0}X_{t+\\delta}=X_t+\\mathcal{N}(0,\\sigma_\\delta^2)$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Markov chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Returning to the discrete time, discrete state stochastic process, if we assume $X_0,X_1,\\cdots$ are independent, then\n",
    "\n",
    "$$\\mathbb{P}(X_{t+1}=j\\mid X_1=i_1,\\cdots,X_t=i_t)=\\mathbb{P}(X_{t+1}=j)$$\n",
    "\n",
    "In words, the past gives us no information, but it is not the reality, and another model is $X_{t+1}$ is dependent on all of the past, but the model will be cumbersome.\n",
    "\n",
    "We define the middle ground: $k$-order Markov chain as\n",
    "\n",
    "$$\\mathbb{P}(X_{t+1}=j\\mid X_1=i_1,\\cdots,X_t=i_t)=\\mathbb{P}(X_{t+1}=j\\mid X_{t-k+1}=i_{t-k+1},\\cdots,X_t=i_t)$$\n",
    "\n",
    "Conditional on $X_{t-k+1},\\cdots,X_t$ the state $X_{t+1}$ is independent of $X_0,\\cdots,X_{t-k}$\n",
    "\n",
    "First-order Markov Chain is the most popular for all Markov chain can be converted to it.\n",
    "\n",
    "$$\\mathbb{P}(X_{t+1}=j\\mid X_1=i_1,\\cdots,X_t=i_t)=\\mathbb{P}(X_{t+1}=j\\mid X_t=i)\\equiv P_{ij}(t)$$\n",
    "\n",
    "$P_{ij}(t)$ is the transition probability of $t$ to $t+1$.\n",
    "\n",
    "\\begin{definition}[Homogeneous Markov chain]\n",
    "\n",
    "If for $\\forall i,j \\in \\mathbb{S}$, the transition probability $P_{ij}(n)$ of a Markov chain $\\{X_t:t\\in\\mathcal{T}\\}$ is a time-invariant, then the Markov chain is homogeneous.\n",
    "\n",
    "\\end{definition}\n",
    "\n",
    "All the Markov chains we discussing are homogeneous."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is natural to place the transition probabilities for a Markov chain in a matrix. This is **transition matrix**, denote $\\mathbf{P}$.\n",
    "\n",
    "$$\\mathbf{P}=\\begin{bmatrix}\n",
    "P_{00}&P_{01}&P_{02}&\\cdots\\\\\n",
    "P_{10}&P_{11}&P_{12}&\\cdots\\\\\n",
    "P_{20}&P_{21}&P_{22}&\\cdots\\\\\n",
    "\\vdots&\\vdots&\\vdots&\\ddots\\\\\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "We call a Markov chain **finite** if $\\mathbb{S}$ consists of a finite number of states.\n",
    "\n",
    "\\begin{property}\n",
    "\n",
    "$$\\sum_jP_{ij}=1$$\n",
    "\n",
    "$$\\sum_j\\mathbb{P}({X_{t+1}=j\\mid X_t=i})=1$$\n",
    "\n",
    "\\end{property}\n",
    "\n",
    "Let \n",
    "\n",
    "$$P_{ij}(n)=\\mathbb{P}({X_{m+n}=j\\mid X_m=i})$$\n",
    "\n",
    "be the probability of going from state $i$ to $j$ in $n$ steps. And $\\mathbf{P}_n$ be the $n$-step transition matrix.\n",
    "\n",
    "\\begin{theorem}[The Chapman-Kolmogorov equations]\n",
    "\n",
    "The $n$ step probabilities satisfy\n",
    "\n",
    "$$P_{ij}(m+n)=\\sum_kP_{ik}(m)P_{kj}(n)$$\n",
    "\n",
    "\\end{theorem}\n",
    "\n",
    "\\begin{proof}\n",
    "\n",
    "Recall the chain rule of probability:\n",
    "\n",
    "$$\\mathbb{P}(X=x,Y=y\\mid Z=z)=\\mathbb{P}(X=x\\mid Z=z)\\mathbb{P}(Y=y\\mid X=x,Z=z)$$\n",
    "\n",
    "and the law of total probability:\n",
    "\n",
    "$$\\mathbb{P}(X=x)=\\sum_y\\mathbb{P}(X=x,Y=y)$$\n",
    "\n",
    "\n",
    "\\begin{align*}\n",
    "P_{ij}(m+n) &= \\mathbb{P}(X_{m+n}=j\\mid X_0=i)\\\\\n",
    "&=\\sum_k \\mathbb{P}(X_{m+n}=j,X_m=k\\mid X_0=i)\\\\\n",
    "&=\\sum_k \\mathbb{P}(X_{m+n}=j\\mid X_m=k,X_0=i)\\mathbb{P}(X_{m}=k\\mid X_0=i)\\\\\n",
    "&=\\sum_k \\mathbb{P}(X_{m+n}=j\\mid X_m=k)\\mathbb{P}(X_{m}=k\\mid X_0=i)\\\\\n",
    "&=\\sum_kP_{ik}(m)P_{kj}(n)\n",
    "\\end{align*}\n",
    "\n",
    "And $\\mathbf{P}_{m+n}=\\mathbf{P}_{m}\\mathbf{P}_{n}$, where $\\mathbf{P}_{n}=\\mathbf{P}^{n}$.\n",
    "\\end{proof}\n",
    "\n",
    "\\begin{definition}[Absorbing states]\n",
    "\n",
    "A state $j$ of a Markov chain is called **absorbing** if $P_{jj}=1$, i.e. if the chain reaches state $j$, it is stuck there forever.\n",
    "\\end{definition}\n",
    "\n",
    "\\begin{definition}[Reaching probability]\n",
    "\n",
    "The reaching probability $f_{ij}$ is the probability that the Markov chain will reach state $j$ at any time in future if it starts at state $i$.\n",
    "\n",
    "$$f_{ij}=\\mathbb{P}(X_n=j\\text{ for some } n > 0 \\mid X_0=i )$$\n",
    "\n",
    "\\end{definition}\n",
    "\n",
    "\\begin{definition}[Recurrent and transient]\n",
    "\n",
    "If $f_{ii}=1$, then state $i$ is recurrent.\n",
    "\n",
    "If $f_{ii}<1$, then the state is transient.\n",
    "\\end{definition}\n",
    "\n",
    "\\begin{theorem}\n",
    "\n",
    "The expected total number of visits to state $j$ is\n",
    "\n",
    "$$\\mathbb{E}\\big[\\sum_{k=0}^\\infty\\mathbb{I}\\{X_k=j\\}\\mid X_0=i\\big] = \\sum_{k=0}^\\infty P_{ij}(k)$$\n",
    "\n",
    "\\end{theorem}\n",
    "\n",
    "\\begin{proof}\n",
    "\n",
    "Define \n",
    "\n",
    "$$\n",
    "y_k=\n",
    "\\begin{align*}\n",
    "1, &\\text{if in state } j \\text{ at time } k \\\\\n",
    "0, &\\text{otherwise}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "\n",
    "\\begin{align*}\n",
    "\\mathbb{E}\\big[\\sum_{k=0}^\\infty\\mathbb{I}\\{X_k=j\\}\\mid X_0=i\\big]&=\\sum_{k=0}^\\infty\\mathbb{E}\\big[y_k\\mid X_0=i\\big]\\\\\n",
    "&=\\sum_{k=0}^\\infty\\mathbb{P}\\big(y_k=1\\mid X_0=i\\big)\\\\\n",
    "&=\\sum_{k=0}^\\infty\\mathbb{P}\\big(X_k=j\\mid X_0=i\\big)\\\\\n",
    "&=\\sum_{k=0}^\\infty P_{ij}(k)\n",
    "\\end{align*}\n",
    "\n",
    "\\end{proof}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{theorem}\n",
    "\n",
    "A state $i$ is recurrent if and only if $\\sum_{k=0}^\\infty P_{ii}(k) = \\infty$.\n",
    "\n",
    "\\end{theorem}\n",
    "\n",
    "\\begin{proof}\n",
    "\n",
    "**Part I**\n",
    "\n",
    "If state $i$ is recurrent then starting at state $i$ will return to $i$ with probability $1$. Since this is a Markov chain, once back in $i$ forget past and restart the process from state $i$. Repeating this argument, the expected number of visit to $i$ from $i$ is infinite. Hence,\n",
    "\n",
    "$$\\sum_{k=0}^\\infty P_{ii}(k) =\\infty$$\n",
    "\n",
    "**Part II**\n",
    "\n",
    "Start in state $i$ and every time we return to state $i$ we are effectively restarting the process again. Consider a visit to state $i$ as a new trail, just like a geometric RV.\n",
    "\n",
    "If chain returns to $i$ called \"failure\" and does not return called \"success\". And $\\mathbb{P}(\\text{success})=1-f_{ii}$. The number of trails tosee  first \"success\" is the number of visits to state $i$.\n",
    "\n",
    "Therefore, \n",
    "\n",
    "$$\\mathbb{E}\\big[\\text{number of visits to state } i\\big]=\\frac{1}{1-f_{ii}}$$\n",
    "\n",
    "If $\\sum_{k=0}^\\infty P_{ii}(k) < \\infty$, then $\\frac{1}{1-f_{ii}}<\\infty$, it means $f_{ii}<1$, in other words, $i$ is not recurrent.\n",
    "\n",
    "\\end{proof}\n",
    "\n",
    "For two different states $i$ and $j$, we say that the state $j$ is accessible from $i$ if $f_{ij}>0$, denote $i\\to j$. If $i\\to j$ and $j\\to i$ then we say $i$ and $j$ are communicate, denote $i\\leftrightarrow j$. All states that communicate with each other form a class. An important property of Markov chain is that **every state belongs to only ine class**. \n",
    "\n",
    "\\begin{definition}[Irreducible]\n",
    "A Markov chain with only one class is called irreducible.\n",
    "\\end{definition}\n",
    "\n",
    "\\begin{theorem}\n",
    "\n",
    "If $i\\leftrightarrow j$ that the state $i$ is reccurent, the state $j$ is also recurrent.\n",
    "\n",
    "\\end{theorem}\n",
    "\n",
    "\\begin{proof}\n",
    "\n",
    "$i$ is reccurent, then $f_{ii}=1$, and $i\\leftrightarrow j$ implies $f_{ij}>0,f_{ji}>0$.\n",
    "\n",
    "Consider a Markov chain starts at $i$ reaching $j$. $f_{ji}=1$ because $i$ is reccurent, it must return to $i$ w.p. 1.\n",
    "\n",
    "Consider a Markov chain starts at $i$ reaching $i$. It is sure that chain hits $j$ because of the communication.\n",
    "\n",
    "Hence $f_{jj}=1$.\n",
    "\n",
    "\\end{proof}\n",
    "\n",
    "From the discussion, we know transience and recurrent are the group properties."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "68px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
